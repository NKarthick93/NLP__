{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JD_Matcher_final_pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **JD Matcher with Resume**\n",
        "In this code, we have used rules based and dictionary based approach to match the resume with a Job description.\n",
        "**Our approach:**\n",
        "Step1: First we extract all the necessary information from JD\n",
        "Step2: Then extract relevant information that a JD is needed to match is extracted.\n",
        "Step3: At the last we have build some rules, the rules are designed under the guidance of experts from our hiring team.\n",
        "Step: Finally we give the relevant matching final socre as well as the matching scores for all skills.\n",
        "\n",
        "**Developed By:**\n",
        "1. Rohit Narain (Senior Deep Learning Engineer, DatatoBiz )helped in concept building\n",
        "2. Karthick N. (Deep Learning Intern, DatatoBiz) Main code contributed in coding part."
      ],
      "metadata": {
        "id": "uZ_e88FhJzQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaW4CapqTjEE",
        "outputId": "fe1512e2-ed55-4ad0-9351-11061c32bb3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Installing Dependencies**"
      ],
      "metadata": {
        "id": "0lVsb3xfLJ5T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkB5H0pNJyfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89d8fbfd-e1eb-46c8-c231-f0de9ab5966b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer.six-20211012-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 5.4 MB/s \n",
            "\u001b[?25hCollecting cryptography\n",
            "  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 45.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from pdfminer.six) (3.0.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography->pdfminer.six) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography->pdfminer.six) (2.21)\n",
            "Installing collected packages: cryptography, pdfminer.six\n",
            "Successfully installed cryptography-36.0.1 pdfminer.six-20211012\n",
            "Collecting docx2txt==0.8\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "Building wheels for collected packages: docx2txt\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3980 sha256=a740cd5299ec9bdf97074ec30bc6b70a627e9c60fe29bf4ee71489cf4d6617d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/20/b2/473e3aea9a0c0d3e7b2f7bd81d06d0794fec12752733d1f3a8\n",
            "Successfully built docx2txt\n",
            "Installing collected packages: docx2txt\n",
            "Successfully installed docx2txt-0.8\n"
          ]
        }
      ],
      "source": [
        "!pip install pdfminer.six\n",
        "!pip install docx2txt==0.8"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing Necessary Libraries**"
      ],
      "metadata": {
        "id": "acQtE0KxLQga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import docx2txt\n",
        "from pdfminer.high_level import extract_text\n",
        "import re\n",
        "import string\n",
        "import pandas as pd\n",
        "from collections import OrderedDict"
      ],
      "metadata": {
        "id": "c-ItsjWGLWZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reading resume and Job description**\n",
        "**Note:**\n",
        "Please keep in mind we are only supporting .docx and .pdf format for now. So please give the job description and resume in this prescribed format."
      ],
      "metadata": {
        "id": "dL1Q1ERTLa7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path1 = '/content/RohitResume(1).docx'\n",
        "path2 = '/content/drive/MyDrive/JDs/Deep Learning Engineer.docx.pdf'"
      ],
      "metadata": {
        "id": "TrGef7TGLvIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Codes to read the text from PDF and docx file**"
      ],
      "metadata": {
        "id": "EarbHTz_L0fu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting docx,pdf into Text\n",
        "def get_text(file):\n",
        "    File = file\n",
        "    text = []\n",
        "    if File[-5:] == '.docx':\n",
        "        text = docx2txt.process(File)\n",
        "    elif File[-4:] == '.pdf':\n",
        "        text = extract_text(File)\n",
        "    else:\n",
        "        return \"Sorry! the file format is not supported. The input supports only (DOCX, PDF) formats.\"\n",
        "    return \" \".join(text.split('\\n'))  "
      ],
      "metadata": {
        "id": "LjCfo957MBtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Codes to extract Relevant information from JD and Resume**\n",
        "The information includes:\n",
        "From JD:\n",
        "We are extracting skills mentioned in resume\n",
        "Decision words e.g. Minimum, Atleast, Maximum, Good To have and Good knowldege etc.\n",
        "Experiece leavl if mentioned in JD for each skills or overall exp for that position.\n",
        "From Resume:\n",
        "We are extractuing all skills \n",
        "We are extracting exp for all skills \n",
        "overall exp of cnadidate to match with JD\n",
        "additional skills if any"
      ],
      "metadata": {
        "id": "PAcPjAIWMQFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skills_dict = {'microsoft word', 'data analysis', 'transformers', 'numpy', 'numpy', 'ms sql', 'natural language processing', 'tensorflow and keras',\n",
        "          'sql', 'sql server', 'css', 'javascript', 'spyder', 'pytorch', 'tableau', 'perl', 't-sql', 'machine learning', 'c++', 'c language', 'c program', 'c programming',\n",
        "          'data science', 'aws', 'excel', 'c#.net', 'anaconda', 'scikit learn', 'seaborn', 'visual basic.net', 'python', 'oracle', 'db2',\n",
        "          'html', 'php', 'pandas', 'word', 'aws ec2', 'python (ide)', 'java', 'keras','microsoft office', 'nlp', 'ruby', 'power bi', 'matplotlib',\n",
        "          'data visualizations', 'aws lambda', 'postgres sql', 'mysql', 'tensorflow', 'jupyter',\"c++\", \"sql\", \"python\", \"java\", \"r language\", \"facebook\", \"html\", \"ladder\", \"javascript\", \"servers\", \"network security\", \"big data\", \"algorithms\", \n",
        "          \"spark\", \"sas\", \"artificial intelligence\", \"ruby\", \"algorithms\", \"analytical skills\", \"big data\", \"compiling statistics\",\n",
        "          \"data analytics\", \"data mining\", \"database design\", \"database management\", 'Neural Networks', \n",
        "          \"quantitative research\", \"quantitative reports\", \"statistical analysis\",  \"computing\", \n",
        "          \"customer support\", \"debugging\", \"design\",  \"html\",\"information technology\", \n",
        "          \"network architecture\", \"network security\", \"networking\", \"operating systems\", \"programming\", \n",
        "          \"systems analysis\", \"technical support\", \"testing\", \"search engine optimization\", \"web analytics\", \"automated marketing software\",\n",
        "          \"subject matter experts\",\"microsoft office\",  \"customer relationship management\", \"cloud/saas services\", \"database management\",\n",
        "          \"telecommunications\", \"human resources software\", \"enterprise resource planning software\", \"database software\", \"query software\",\n",
        "          \"medical coding\", \"sonography\", \"structural analysis\", \"artificial intelligence\", \n",
        "          \"ms office\", \"ms word\",  \"ms excel\", \"ms powerpoint\",  \"ms outlook\",  \"ms access\", \"ms onenote\",\n",
        "          \"google drive\",  \"google docs\", \"google sheets\", \"google forms\", \"google slides\", \"writing\",  \"wordpress\", \"seo\",\n",
        "          \"spreadsheets\",  \"excel\",  \"google sheets\",  \"openoffice\", \"comparative analyses\", \"pivot tables\",  \"macros\", \"link to database\",\n",
        "          \"graphical photoshop\",  \"illustrator, indesign\", \"acrobat\", \"corel draw\", \"web\", \"deep learning\", \".net\"\n",
        "          'neural networks','seaborn','scrpay','tessract','opencv, computer vision, cv','pyspyder', 'eda', 'exploratory data analysis', 'jyputer notebook',\n",
        "          'anaconda','pycharm', 'google colab, colab', 'vs code', 'heroku', 'matlab, matlab', 's3', 'sqs', 'arduino, raspberry pi', 'oops','photoshop',\n",
        "          'nodejs, nodejs', 'reactjs', 'expressjs', 'ms access', 'generative adversial network, gan', 'mongo db', 'visual studio', 'ms excel', 'ms access',\n",
        "          'ms word', 'ms powerpoint', 'idle', 'python 3.4', 'python 3.6', 'python 2.6', 'python 3.7', 'linear regression', 'regression algorithms', 'logistic regression',\n",
        "          'random forest', 'decision trees', 'ada boost,', 'gradient boost', 'knn','k means clustering', 'density based clustering', 'hierarchal clustering', 'naive bayes', \n",
        "          'support vector machines', 'xg boost', 'pca', 'tsne' ,'time series', 'alexnet', 'vggnet', 'residual network, inception', 'network,rnn & lstm', 'rcnn',\n",
        "          'tfod framework', 'android', 'algo & ds', 'data structures and alogorithm','data structures', 'qt creator', 'github,', 'quantum gis' 'mathematical modeling', 'statistical modeling,','hadoop,mapreduce', \n",
        "          \"rcnn\",'alexanet','resnet','deepar','pca','aws sagemaker', 'seo', 'sem', 'mailchimp', 'wordpress', 'wix', 'hubspot',\n",
        "          'Marketing Strategy','Competitor Analysis', 'Social Media Marketing', 'Search Engine Optimization', 'Search Engine Management', 'Web based Analytics',\n",
        "          'Search Marketing, Social Media', 'Marketing, App Promotion, Video', 'Advertising & Data Analytics', 'SEM (Google Ads, Bing Ads), SMM (Facebook Advertisement) and SEO',\n",
        "          'Re-marketing (Static & Dynamic)', 'Brand Promotion', 'Budget Allocation', 'Product listing ads', 'A/B Split Testing', 'Lead Generation', 'Analysis and Reporting (Google Analytics & Google Ads Reporting)',\n",
        "          'Amazon Sponsored Ads', 'Facebook Ads', 'Google Ads', 'ORM', 'Brand Development', 'Political Campaign', 'Website Designing', 'Marketing Strategy',\n",
        "          'SEO', 'Team Leader','Sales& BD Ops, Strategy, Marketing', 'Automate Marketing & Prospecting', 'Secondary Market Research', 'Business Analytics/BI/Reports', 'Technical Delivery (SDLC, Agile)',\n",
        "          'Communication(Hindi, English)', 'Leadership', 'Problem Solving', 'Resilience', 'Persistence', 'Public Speaking', 'Teamwork',\n",
        "          'python', 'bash', 'sql', 'opencv', 'spacy', 'nltk', 'scikit-learn', 'numpy', 'pandas', 'selenium', 'beautiful soup', 'image processing', 'image augmentation', 'object detection', 'image classification',\n",
        "          'rnns', 'grus', 'lstms','sentiment analysis','named entity recognition (ner)', 'text classification', 'nvidia tlt-kit', 'deepstream', 'jetson' , 'nano device',\n",
        "          'analytical ability','adaptability','critical thinking','decision making','devising strategic plans to expand sales','swot analysis','scenario planning','project management',\n",
        "          'sales forecasting','teamwork','attention management','tracking industry trends','marketing','creativity communication','client management content writing','resiliency time management',\n",
        "          'team player leadership','relationship building','consumer engagement team management','social media campaign building','tensorflow', 'keras', 'pytorch', 'caffe', 'mxnet'}    \n",
        "\n",
        "# Extracting the skills from the text\n",
        "def get_matches(s, keys, include_duplicates=False):\n",
        "     pattern = re.compile('|'.join(map(re.escape, keys)))\n",
        "     all_matches = pattern.findall(s, re.IGNORECASE)\n",
        "     if not include_duplicates:\n",
        "         all_matches = list(OrderedDict.fromkeys(all_matches).keys())\n",
        "     else:\n",
        "         return None\n",
        "     return all_matches\n",
        "\n",
        "# Extracting Experience\n",
        "def extract_experience_from_jd(path):\n",
        "    regex1 = r\"(\\d+\\.?\\-\\+?\\d*?)\\s+years\" \n",
        "    regex2 = r\"(\\d+\\.?\\+?\\d*?)\\s+years?\\s+.*?\\s+experience\"\n",
        "    regexList = [regex1, regex2]\n",
        "    for x in regexList:\n",
        "        if re.findall(x, path):\n",
        "            some_list = re.findall(x, path)     \n",
        "            for y in some_list:\n",
        "                found_regex_list = []\n",
        "                found_regex_list.append(y)\n",
        "                return found_regex_list   \n",
        "#Cleaning_jd\n",
        "def cleaning_jd(text):\n",
        "    text = text.strip() # Stripping text\n",
        "    text = re.sub('[^A-Za-z0-9.,\\ ()-?><!$*_=+\\{\\}\\/;`|₹\\]\\[\\n%&\"\\']+', '', text) # remove the special characters \n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text) # remove the punctuation \n",
        "    text = re.sub('\\n+','\\n', text) # remove the next line characters\n",
        "    text = re.sub(' +', ' ', text)  # remove the extra spaces\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    text = text.replace('•', '', -1) # remove the bullet points\n",
        "    text = re.sub(' +', ' ', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "# cleaning education entities\n",
        "def edu_cleaning_jd (extracted_text):\n",
        "  # Note: We are ignoring (#, ^) and other special chars\n",
        "  # Stripping text\n",
        "  extracted_text = extracted_text.strip()\n",
        "  # handling web links starting with 'http'\n",
        "  extracted_text = re.sub(r'http\\S+', '', extracted_text)\n",
        "  # handling web links ending with extensions like (.com), (.in) etc.\n",
        "  extracted_text = re.sub(r'[\\S]+\\.(net|com|org|info|edu|gov|in|ai|uk|de|ca|jp|fr|au|us|ru|ch|it|nel|se|no|es|mil)[\\S]*\\s?','',extracted_text)\n",
        "  # handling special characters\n",
        "  extracted_text = re.sub('[^A-Za-z0-9.,\\ :()-?><!$*_=+\\{\\}\\/;`~@|₹\\]\\[\\n%&\"\\']+', '', extracted_text)\n",
        "  # handling extra next line chars\n",
        "  extracted_text = re.sub('\\n+','\\n', extracted_text)\n",
        "  # handling extra spaces\n",
        "  extracted_text = re.sub('  +', ' ', extracted_text)\n",
        "  # remove reference numbers\n",
        "  extracted_text = re.sub(r'\\[\\d+\\]', ' ', extracted_text)\n",
        "  extracted_text = re.sub(' +', ' ', extracted_text)\n",
        "  extracted_text =  re.sub(\"\\n\",\" \",extracted_text)\n",
        "  # handling bullet point\n",
        "  extracted_text = extracted_text.replace('•', '', -1)\n",
        "  return extracted_text\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Function to convert  \n",
        "def listToString_jd(path): \n",
        "    str1 = \"  \".join(path) \n",
        "    return str1\n",
        "\n",
        "# list\n",
        "my_list_jd = [\"Minimum\",\"minimum\", \"Atleast\",\"atleast\",\"Maximum\",\"maximum\",\"Overall\",\"overall\",\"having\",\"Having\",\"Good Knowledge\", \"good knowledge\"]\n",
        "\n",
        "# Extracting Experience\n",
        "def extract_experience_resume(path):\n",
        "    regex1 = r\"(\\d+\\.?\\-\\+?\\d*?)\\s+years\" \n",
        "    regex2 = r\"(\\d+\\.?\\+?\\d*?)\\s+years?\\s+.*?\\s+experience\"\n",
        "    regexList = [regex1, regex2]\n",
        "    for x in regexList:\n",
        "        if re.findall(x, path):\n",
        "            some_list = re.findall(x, path)     \n",
        "            for y in some_list:\n",
        "                found_regex_list = []\n",
        "                found_regex_list.append(y)\n",
        "                return found_regex_list    \n",
        "\n",
        "#Removing whitespaces\n",
        "def remove_resume(text):\n",
        "    text = re.sub(' +', ' ', text)\n",
        "    text = text.replace('\\t', '', -1)\n",
        "    text = text.replace('/', ' ', -1)\n",
        "    return text\n",
        "\n",
        "#converting tuple      \n",
        "def conv_resume(x):\n",
        "  try:\n",
        "    y = '{} - {}'.format(x[0][0], x[0][1])\n",
        "    for i in range(1, len(x)):\n",
        "        y += '\\n{} - {}'.format(x[i][0], x[i][1])\n",
        "    return y \n",
        "  except:\n",
        "    return \"An exception occurred\"  \n",
        "\n",
        "\n",
        "# Extracting the skills from the text\n",
        "def month_year(s):\n",
        "     months = r\"january|Jan|January|jan|jan.|February|Feb|february|feb|feb.|Feb.|March|march|mar|Mar|mar.|Mar.|April|april|Apr|apr|apr.|Apr.|May|may|may.|May.|june|June|June |jun.|Jun.|jun|Jun|july|Jul|jul|July|July |july.|July.|august|August|August.|august.|Aug|aug|Aug.|aug.|september|September|sep|sept|Sep|Sept.|sept.|october|October||Oct|oct|oct.|Oct.|november|November|nov|Nov|nov|Nov.|december|December|dec|Dec|dec.|Dec.\"\n",
        "     pattern = re.compile(fr\"(?i)((?:{months}) *\\d{{2,4}})  *(?:-|–|to)  *(Present|till now|Till Date|present|Till now|Till Now|Current|current|At present|at present|(?:{months}) *\\d{{2,4}})\")\n",
        "     all_matches = pattern.findall(s, re.IGNORECASE)\n",
        "     return list(all_matches)\n",
        "\n",
        "\n",
        "#parsing date\n",
        "def parse_date(x, fmts=(\"%b %Y\", \"%B %Y\")):\n",
        "    for fmt in fmts:\n",
        "        try:\n",
        "            return datetime.strptime(x, fmt)\n",
        "        except ValueError:\n",
        "            pass\n",
        "def total_experience_companies(path):\n",
        "  try:\n",
        "    months = \"|\".join(calendar.month_abbr[1:] + calendar.month_name[1:])\n",
        "    pattern = fr\"(?i)((?:{months}) *\\d{{2,4}}) *(?:-|–|to) *(present|(?:{months}) *\\d{{2,4}})\"\n",
        "    total_experience = None\n",
        "    for start, end in re.findall(pattern, path):\n",
        "        if end.lower() == \"present\":\n",
        "            today = datetime.today()\n",
        "            end = f\"{calendar.month_abbr[today.month]} {today.year}\"\n",
        "        duration = relativedelta(parse_date(end), parse_date(start))\n",
        "        if total_experience:\n",
        "            total_experience += duration\n",
        "        else: \n",
        "            total_experience = duration\n",
        "        print(f\"{start}-{end} ({duration.years} years, {duration.months} months)\")\n",
        "    if total_experience:\n",
        "        print(f\"total experience:  {total_experience.years} years, {total_experience.months} months\")\n",
        "    else:\n",
        "        print(\"couldn't parse text\") \n",
        "  except:\n",
        "    return \"Format not accepted\" \n",
        "\n",
        "\n",
        "# Text preprocessing \n",
        "def date_cleaning_resume(text):\n",
        "  try:\n",
        "    text = text.replace('.', '')\n",
        "    text = text.replace('till now', 'present') \n",
        "    text = text.replace('Till now', 'present')\n",
        "    text = text.replace('Present', 'present')\n",
        "    text = text.replace('Current', 'present')\n",
        "    text = text.replace('current', 'present')\n",
        "    text = text.replace('At present', 'present')\n",
        "    text = text.replace('Till Date', 'present')\n",
        "    text = text.replace('till Date', 'present')\n",
        "    text = re.sub('(\\d+(\\.\\d+)?)', r' \\1 ', text).strip()\n",
        "    return text\n",
        "  except:\n",
        "    return \"couldn't parse text\"\n",
        "\n",
        "\n",
        "\n",
        "#Remove ordinal data\n",
        "def ordinal_resume(path):\n",
        "    a_string = path\n",
        "    remove_characters = [\"1st\", \"2nd\", \"3rd\", \"4th\", \"5th\", \"6th\", \"7th\", \"8th\", \"9th\", \"10th\", \"11th\", \"12th\", \"13th\", \"14th\", \"15th\", \"16th\", \"17th\", \"18th\",\"19th\", \"20th\", \"21st\", \"22nd\", \"23rd\", \"24th\", \"25th\", \"26th\", \"27th\", \"28th\", \"29th\", \"30th\", \"31st\"]\n",
        "    for character in remove_characters:\n",
        "        a_string = a_string.replace(character, \"\")\n",
        "    return a_string\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#two digit converstion\n",
        "def two_digit_resume(path):\n",
        "  try:\n",
        "    months = \"|\".join(calendar.month_abbr[1:] + calendar.month_name[1:])\n",
        "    pattern = fr\"(?i)((?:{months}) *\\d{{2}}) *(?:-|–) *(present|(?:{months}) *\\d{{2}})\"\n",
        "    pattern2 = fr\"(?i)((?:{months}) *\\d{{4}}) *(?:-|–) *(present|(?:{months}) *\\d{{4}})\"\n",
        "    four_dig = re.findall(pattern2, path)\n",
        "    four_dig = [tuple(x) for x in four_dig]\n",
        "    h = []\n",
        "    h.extend(four_dig)\n",
        "    for start in re.findall(pattern, path):  \n",
        "        start = list(start)\n",
        "        str1 = ','.join(start)\n",
        "        s1 = '20'.join(str1.split())\n",
        "        s2 = re.sub(r'(?<=[.,]) (?=[^\\s])', r' ',s1)\n",
        "        str2 = list(s2.split(\" \"))\n",
        "        str2 = [x for s in str2 for x in s.split()]\n",
        "        str2 = [x for xs in str2 for x in xs.split(',')]\n",
        "        str2 = tuple(str2)\n",
        "        h.append(str2)\n",
        "    return h\n",
        "  except:\n",
        "    return \"Incorrect Format\" \n",
        "\n",
        "\n",
        "# Text preprocessing \n",
        "def cleaning_resume(text):\n",
        "    text = text.strip() # Stripping text\n",
        "    text = re.sub('[^A-Za-z0-9.,\\ ()-?><!$*_=+\\{\\}\\/;`|₹\\]\\[\\n%&\"\\']+', '', text) # remove the special characters \n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text) # remove the punctuation \n",
        "    text = re.sub('\\n+','\\n', text) # remove the next line characters\n",
        "    text = re.sub(' +', ' ', text)  # remove the extra spaces\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    text = text.replace('•', '', -1) # remove the bullet points\n",
        "    text = re.sub(' +', ' ', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "\n",
        "# cleaning education entities\n",
        "def edu_cleaning_resume(extracted_text):\n",
        "  # Note: We are ignoring (#, ^) and other special chars\n",
        "  # Stripping text\n",
        "  extracted_text = extracted_text.strip()\n",
        "  # handling web links starting with 'http'\n",
        "  extracted_text = re.sub(r'http\\S+', '', extracted_text)\n",
        "  # handling web links ending with extensions like (.com), (.in) etc.\n",
        "  extracted_text = re.sub(r'[\\S]+\\.(net|com|org|info|edu|gov|in|ai|uk|de|ca|jp|fr|au|us|ru|ch|it|nel|se|no|es|mil)[\\S]*\\s?','',extracted_text)\n",
        "  # handling special characters\n",
        "  extracted_text = re.sub('[^A-Za-z0-9.,\\ :()-?><!$*_=+\\{\\}\\/;`~@|₹\\]\\[\\n%&\"\\']+', '', extracted_text)\n",
        "  # handling extra next line chars\n",
        "  extracted_text = re.sub('\\n+','\\n', extracted_text)\n",
        "  # handling extra spaces\n",
        "  extracted_text = re.sub('  +', ' ', extracted_text)\n",
        "  # remove reference numbers\n",
        "  extracted_text = re.sub(r'\\[\\d+\\]', ' ', extracted_text)\n",
        "  extracted_text = re.sub(' +', ' ', extracted_text)\n",
        "  extracted_text =  re.sub(\"\\n\",\" \",extracted_text)\n",
        "  # handling bullet point\n",
        "  extracted_text = extracted_text.replace('•', '', -1)\n",
        "  return extracted_text\n",
        "\n",
        "\n",
        "\n",
        "# Function to convert  \n",
        "def listToString_resume(path): \n",
        "    str1 = \"  \".join(path) \n",
        "    return str1\n",
        "\n",
        "# Companies names\n",
        "def company_names_resume(path):\n",
        "    reg = re.compile(r\"\\b[a-zA-Z]\\w+(?:\\.com?)?(?:[ -]+(?:&[ -]+)?[A-Z]\\w+(?:\\.com?)?){0,1}[,\\s]+(?i:ltd|pvt|labs|consultancy services|technologies solutions|solution llp|fintech|Pvt.Ltd.|private limited|limited|software solutions|corporation limited|research and analytics|llc|inc|plc(?:rp)?|holding|gmbh)\\b\")    \n",
        "    return re.findall(reg, path) \n"
      ],
      "metadata": {
        "id": "Xh43kAuqM2BB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Rules to Match Jd with Resume**\n",
        "\n"
      ],
      "metadata": {
        "id": "edFDwNLrNGgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Rules setting\n",
        "def matching_score(row):\n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD'] == 'NaN':\n",
        "      if row['WORK_EXPERIENCE_JD'] == row['WORK_EXPERIENCE_RESUME']:\n",
        "        return 100\n",
        "  if row['SKILLS_FROM_JD'] != 'NaN': \n",
        "    if row['SKILL_FROM_RESUME'] == 'NaN':\n",
        "      return 0         \n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD'] == 'NaN':\n",
        "      if row['WORK_EXPERIENCE_JD'] > row['WORK_EXPERIENCE_RESUME']:\n",
        "          return row['WORK_EXPERIENCE_RESUME']/row['WORK_EXPERIENCE_JD']*100\n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN': \n",
        "    if row['DECISION_WORDS_JD'] == 'At least':\n",
        "      if row['WORK_EXPERIENCE_JD'] > row['WORK_EXPERIENCE_RESUME']:\n",
        "          return row['WORK_EXPERIENCE_RESUME']/row['WORK_EXPERIENCE_JD']*100 \n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD'] == 'Minimum':\n",
        "      if row['WORK_EXPERIENCE_JD'] > row['WORK_EXPERIENCE_RESUME']:\n",
        "          return row['WORK_EXPERIENCE_RESUME']/row['WORK_EXPERIENCE_JD']*100\n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN': \n",
        "    if row['DECISION_WORDS_JD'] == 'Maximum':\n",
        "      if row['WORK_EXPERIENCE_JD'] > row['WORK_EXPERIENCE_RESUME']:\n",
        "          return row['WORK_EXPERIENCE_RESUME']/row['WORK_EXPERIENCE_JD']*100\n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD'] == 'Good Knowledge':\n",
        "      if row['WORK_EXPERIENCE_JD'] > row['WORK_EXPERIENCE_RESUME']:\n",
        "          return row['WORK_EXPERIENCE_RESUME']/row['WORK_EXPERIENCE_JD']*100 \n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD'] == 'Having':\n",
        "      if row['WORK_EXPERIENCE_JD'] > row['WORK_EXPERIENCE_RESUME']:\n",
        "          return row['WORK_EXPERIENCE_RESUME']/row['WORK_EXPERIENCE_JD']*100 \n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN': \n",
        "    if row['DECISION_WORDS_JD'] == 'NaN':\n",
        "      if row['WORK_EXPERIENCE_JD'] < row['WORK_EXPERIENCE_RESUME']:\n",
        "          return 100\n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD'] == 'At least':\n",
        "      if row['WORK_EXPERIENCE_JD'] < row['WORK_EXPERIENCE_RESUME']:\n",
        "          return 100 \n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD'] == 'Minimum':\n",
        "      if row['WORK_EXPERIENCE_JD'] < row['WORK_EXPERIENCE_RESUME']:\n",
        "          return 100\n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD'] == 'Maximum':\n",
        "      if row['WORK_EXPERIENCE_JD'] < row['WORK_EXPERIENCE_RESUME']:\n",
        "          return 100\n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD'] == 'Good Knowledge':\n",
        "      if row['WORK_EXPERIENCE_JD'] < row['WORK_EXPERIENCE_RESUME']:\n",
        "          return 100 \n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD'] == 'Having':\n",
        "      if row['WORK_EXPERIENCE_JD'] < row['WORK_EXPERIENCE_RESUME']:\n",
        "          return 100   \n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD'] == 'At least':\n",
        "      if row['WORK_EXPERIENCE_JD'] == row['WORK_EXPERIENCE_RESUME']:\n",
        "          return 100 \n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD'] == 'Minimum':\n",
        "      if row['WORK_EXPERIENCE_JD'] == row['WORK_EXPERIENCE_RESUME']:\n",
        "          return 100\n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD'] == 'Maximum':\n",
        "      if row['WORK_EXPERIENCE_JD'] == row['WORK_EXPERIENCE_RESUME']:\n",
        "          return 100\n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD']== 'Good Knowledge':\n",
        "      if row['WORK_EXPERIENCE_JD'] == row['WORK_EXPERIENCE_RESUME']:\n",
        "          return 100 \n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD']== 'Having':\n",
        "      if row['WORK_EXPERIENCE_JD'] == row['WORK_EXPERIENCE_RESUME']:\n",
        "          return 100\n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD'] == 'overall':\n",
        "      if row['WORK_EXPERIENCE_JD'] == row['WORK_EXPERIENCE_RESUME']:\n",
        "          return 100\n",
        "          \n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD'] == 'overall':\n",
        "      if row['WORK_EXPERIENCE_JD'] > row['WORK_EXPERIENCE_RESUME']:\n",
        "          return row['WORK_EXPERIENCE_RESUME']/row['WORK_EXPERIENCE_JD']*100 \n",
        "          \n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD'] == 'overall':\n",
        "      if row['WORK_EXPERIENCE_JD'] < row['WORK_EXPERIENCE_RESUME']:\n",
        "          return 100\n",
        "####################################################################################\n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN': \n",
        "    if row['DECISION_WORDS_JD'] == 'atleast':\n",
        "      if row['WORK_EXPERIENCE_JD'] > row['WORK_EXPERIENCE_RESUME']:\n",
        "          return row['WORK_EXPERIENCE_RESUME']/row['WORK_EXPERIENCE_JD']*100 \n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD'] == 'minimum':\n",
        "      if row['WORK_EXPERIENCE_JD'] > row['WORK_EXPERIENCE_RESUME']:\n",
        "          return row['WORK_EXPERIENCE_RESUME']/row['WORK_EXPERIENCE_JD']*100\n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN': \n",
        "    if row['DECISION_WORDS_JD'] == 'maximum':\n",
        "      if row['WORK_EXPERIENCE_JD'] > row['WORK_EXPERIENCE_RESUME']:\n",
        "          return row['WORK_EXPERIENCE_RESUME']/row['WORK_EXPERIENCE_JD']*100\n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD'] == 'good knowledge':\n",
        "      if row['WORK_EXPERIENCE_JD'] > row['WORK_EXPERIENCE_RESUME']:\n",
        "          return row['WORK_EXPERIENCE_RESUME']/row['WORK_EXPERIENCE_JD']*100 \n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD'] == 'having':\n",
        "      if row['WORK_EXPERIENCE_JD'] > row['WORK_EXPERIENCE_RESUME']:\n",
        "          return row['WORK_EXPERIENCE_RESUME']/row['WORK_EXPERIENCE_JD']*100 \n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN': \n",
        "    if row['DECISION_WORDS_JD'] == 'NaN':\n",
        "      if row['WORK_EXPERIENCE_JD'] < row['WORK_EXPERIENCE_RESUME']:\n",
        "          return 100\n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD'] == 'atleast':\n",
        "      if row['WORK_EXPERIENCE_JD'] < row['WORK_EXPERIENCE_RESUME']:\n",
        "          return 100 \n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD'] == 'minimum':\n",
        "      if row['WORK_EXPERIENCE_JD'] < row['WORK_EXPERIENCE_RESUME']:\n",
        "          return 100\n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD'] == 'maximum':\n",
        "      if row['WORK_EXPERIENCE_JD'] < row['WORK_EXPERIENCE_RESUME']:\n",
        "          return 100\n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD'] == 'good knowledge':\n",
        "      if row['WORK_EXPERIENCE_JD'] < row['WORK_EXPERIENCE_RESUME']:\n",
        "          return 100 \n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD'] == 'having':\n",
        "      if row['WORK_EXPERIENCE_JD'] < row['WORK_EXPERIENCE_RESUME']:\n",
        "          return 100   \n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD'] == 'atleast':\n",
        "      if row['WORK_EXPERIENCE_JD'] == row['WORK_EXPERIENCE_RESUME']:\n",
        "          return 100 \n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD'] == 'minimum':\n",
        "      if row['WORK_EXPERIENCE_JD'] == row['WORK_EXPERIENCE_RESUME']:\n",
        "          return 100\n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD'] == 'maximum':\n",
        "      if row['WORK_EXPERIENCE_JD'] == row['WORK_EXPERIENCE_RESUME']:\n",
        "          return 100\n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD']== 'good knowledge':\n",
        "      if row['WORK_EXPERIENCE_JD'] == row['WORK_EXPERIENCE_RESUME']:\n",
        "          return 100 \n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD']== 'having':\n",
        "      if row['WORK_EXPERIENCE_JD'] == row['WORK_EXPERIENCE_RESUME']:\n",
        "          return 100\n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD'] == 'Overall':\n",
        "      if row['WORK_EXPERIENCE_JD'] == row['WORK_EXPERIENCE_RESUME']:\n",
        "          return 100\n",
        "          \n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD'] == 'Overall':\n",
        "      if row['WORK_EXPERIENCE_JD'] > row['WORK_EXPERIENCE_RESUME']:\n",
        "          return row['WORK_EXPERIENCE_RESUME']/row['WORK_EXPERIENCE_JD']*100 \n",
        "          \n",
        "  if row['SKILL_FROM_RESUME'] != 'NaN':\n",
        "    if row['DECISION_WORDS_JD'] == 'Overall':\n",
        "      if row['WORK_EXPERIENCE_JD'] < row['WORK_EXPERIENCE_RESUME']:\n",
        "          return 100"
      ],
      "metadata": {
        "id": "jGrH2nzWNQCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Get The Matching Skills with Score**"
      ],
      "metadata": {
        "id": "X3L2rT6kNW7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "####################################################################################\n",
        "# Function to convert  \n",
        "def listToString(s): \n",
        "    # initialize an empty string\n",
        "    str1 = \" \" \n",
        "   # return string  \n",
        "    return (str1.join(s))\n",
        "\n",
        "# get_matches\n",
        "def waste(li, ki):\n",
        "  result = []\n",
        "  for i in li:\n",
        "      for j in ki:\n",
        "        if i == j:\n",
        "          result.append(i)\n",
        "  return result\n",
        "\n",
        "# matched\n",
        "def dat(a,b):\n",
        "  ar=[]\n",
        "  for x in a:\n",
        "    if x not in b: ar.append('NaN')\n",
        "    elif x in b: ar.append(x)\n",
        "  return ar  \n",
        "\n",
        "## exp\n",
        "def ex(x):\n",
        "  if x == 'None':\n",
        "      return 0.0\n",
        "  else:\n",
        "      return x         \n",
        "#########################################################################################################################################################################\n",
        "\n",
        "def main():\n",
        "  text_res = get_text(path1)\n",
        "  text1_res = cleaning_resume(text_res.lower())\n",
        "  text3_res = edu_cleaning_resume(text_res)\n",
        "  exp_resume = extract_experience_resume(text3_res) \n",
        "  #print(exp_resume) \n",
        "  exp_resume = ex(exp_resume)\n",
        "  skills_resume = get_matches(text1_res,skills_dict)\n",
        "  skills_resume = sorted(skills_resume)\n",
        "  #print(skills_resume)\n",
        "  t = remove_resume(text_res)\n",
        "  t = t.replace('(','')\n",
        "  t = t.replace(')','')\n",
        "  t = t.replace('-',' to ')\n",
        "  t = ordinal_resume(t)\n",
        "  t = month_year(t)\n",
        "  t = conv_resume(t)\n",
        "  t = date_cleaning_resume(t)\n",
        "  t = two_digit_resume(t)\n",
        "  t = conv_resume(t)\n",
        "  t = date_cleaning_resume(t)\n",
        "  total_exp_resume = exp_resume\n",
        "  #print(total_exp_resume)\n",
        "  dataframe_result_res= pd.DataFrame({'SKILLS_FROM_RESUME':  pd.Series(skills_resume), 'WORK_EXPERIENCE_RESUME': pd.Series(exp_resume)})\n",
        "  #print(dataframe_result_res)\n",
        "  ########################################################\n",
        "  text_jd = get_text(path2)\n",
        "  text1_jd = cleaning_jd(text_jd.lower())\n",
        "  text3_jd = edu_cleaning_jd(text_jd)\n",
        "  exp_jd = extract_experience_from_jd(text3_jd)\n",
        "  exp_jd = exp_jd[0]\n",
        "  exp_jd = exp_jd[0]\n",
        "  #print(exp_jd)\n",
        "  skills_jd = get_matches(text1_jd,skills_dict)\n",
        "  skills_jd = sorted(skills_jd)\n",
        "  #print(skills_jd)\n",
        "  decision_jd = get_matches(text3_jd,my_list_jd)\n",
        "  dataframe_result_jd= pd.DataFrame({'SKILLS_FROM_JD':  pd.Series(skills_jd), 'DECISION_WORDS_JD':  pd.Series(decision_jd), 'WORK_EXPERIENCE_JD': pd.Series(exp_jd)})\n",
        "  #print(dataframe_result_jd)\n",
        "  ########################################################\n",
        "  #dataframe_final = [dataframe_result_res,dataframe_result_jd]\n",
        "  Final_data = pd.concat([dataframe_result_jd, dataframe_result_res], axis=1, ignore_index=False)\n",
        "  #print(dataframe_final)\n",
        "  Final_data[['WORK_EXPERIENCE_JD','WORK_EXPERIENCE_RESUME']] = Final_data[['WORK_EXPERIENCE_JD','WORK_EXPERIENCE_RESUME']].fillna(0)\n",
        "  Final_data[['WORK_EXPERIENCE_JD','WORK_EXPERIENCE_RESUME']] = Final_data[['WORK_EXPERIENCE_JD','WORK_EXPERIENCE_RESUME']].astype(float)\n",
        "  Final_data['DECISION_WORDS_JD'] = Final_data['DECISION_WORDS_JD'].fillna('NaN')\n",
        "  Final_data['SKILLS_FROM_JD'] = Final_data['SKILLS_FROM_JD'].fillna('NaN')\n",
        "  Final_data['SKILLS_FROM_RESUME'] = Final_data['SKILLS_FROM_RESUME'].fillna('NaN')\n",
        "  jdskill = Final_data['SKILLS_FROM_JD']\n",
        "  resskill = Final_data['SKILLS_FROM_RESUME']\n",
        "  matched = waste(jdskill,resskill)\n",
        "  #print(matched)\n",
        "  Final_data['RESUMES_SKILLS'] = pd.DataFrame(matched)\n",
        "  Final_data['RESUMES_SKILLS'] = Final_data['RESUMES_SKILLS'].fillna('NaN')\n",
        "  a = Final_data['SKILLS_FROM_JD'].tolist()\n",
        "  b = Final_data['RESUMES_SKILLS'].tolist()\n",
        "  Final_data['SKILL_FROM_RESUME'] = pd.DataFrame(dat(a,b))\n",
        "  Datasets = Final_data[['SKILLS_FROM_JD','SKILL_FROM_RESUME','DECISION_WORDS_JD','WORK_EXPERIENCE_JD','WORK_EXPERIENCE_RESUME']]\n",
        "  Datasets['MATCHING_SCORE'] = Datasets.apply(lambda row: matching_score(row), axis=1 )\n",
        "  #Datasets.to_csv('kar.csv') \n",
        "  print(Datasets.head(15))\n",
        "  per = round(Datasets['MATCHING_SCORE'].mean())\n",
        "  #per = Datasets['MATCHING_SCORE'].mean()\n",
        "  per = str(per)\n",
        "  #Datasets['MATCHING_SCORE'] = Datasets['MATCHING_SCORE'].astype(str)\n",
        "  result = {'The JD and RESUME MATCHING SCORE':per}\n",
        "  print(result)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "     main()"
      ],
      "metadata": {
        "id": "K0L7npcrNfgp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8952c6d-3ea7-46ef-c337-36b23cf4a9cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 SKILLS_FROM_JD  ... MATCHING_SCORE\n",
            "0                    algorithms  ...          100.0\n",
            "1                         caffe  ...            0.0\n",
            "2                  data science  ...          100.0\n",
            "3                 deep learning  ...          100.0\n",
            "4                         keras  ...          100.0\n",
            "5              machine learning  ...          100.0\n",
            "6                         mxnet  ...            0.0\n",
            "7   natural language processing  ...          100.0\n",
            "8                           nlp  ...          100.0\n",
            "9              object detection  ...            0.0\n",
            "10                  programming  ...          100.0\n",
            "11                       python  ...          100.0\n",
            "12                      pytorch  ...            0.0\n",
            "13                         rcnn  ...            0.0\n",
            "14                          NaN  ...            NaN\n",
            "\n",
            "[15 rows x 6 columns]\n",
            "{'The JD and RESUME MATCHING SCORE': '64'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:92: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ]
    }
  ]
}